{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fd28f5-5901-41e0-882e-df6b7167a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (25.1.1)\n",
      "Requirement already satisfied: feedparser in /opt/conda/lib/python3.11/site-packages (6.0.11)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (23.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: selenium in /opt/conda/lib/python3.11/site-packages (4.33.0)\n",
      "Requirement already satisfied: webdriver-manager in /opt/conda/lib/python3.11/site-packages (4.0.2)\n",
      "Requirement already satisfied: playwright in /opt/conda/lib/python3.11/site-packages (1.50.0)\n",
      "Requirement already satisfied: cloudscraper in /opt/conda/lib/python3.11/site-packages (1.2.71)\n",
      "Requirement already satisfied: nest_asyncio in /opt/conda/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.11/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: urllib3~=2.4.0 in /opt/conda/lib/python3.11/site-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in /opt/conda/lib/python3.11/site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in /opt/conda/lib/python3.11/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.4.26 in /opt/conda/lib/python3.11/site-packages (from selenium) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions~=4.13.2 in /opt/conda/lib/python3.11/site-packages (from selenium) (4.13.2)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in /opt/conda/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/conda/lib/python3.11/site-packages (from trio~=0.30.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.11/site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from trio~=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /opt/conda/lib/python3.11/site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/conda/lib/python3.11/site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: pyee<13,>=12 in /opt/conda/lib/python3.11/site-packages (from playwright) (12.1.1)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /opt/conda/lib/python3.11/site-packages (from playwright) (3.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /opt/conda/lib/python3.11/site-packages (from cloudscraper) (3.2.1)\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from cloudscraper) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install feedparser argon2-cffi beautifulsoup4 selenium webdriver-manager playwright cloudscraper nest_asyncio tabulate\n",
    "#!playwright install chromium firefox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0a422a-5301-4066-87fe-af52994b0fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Установка локальных зависимостей для Playwright...\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
      "Fetched 51.9 kB in 0s (202 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
      "Fetched 66.6 kB in 0s (273 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
      "Fetched 7,192 B in 0s (55.8 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxdamage1 amd64 1:1.1.5-2build2 [7,154 B]\n",
      "Fetched 7,154 B in 0s (63.7 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
      "Fetched 80.9 kB in 1s (138 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.22.04.2 [1,347 kB]\n",
      "Fetched 1,347 kB in 0s (2,808 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnspr4 amd64 2:4.35-0ubuntu0.22.04.1 [119 kB]\n",
      "Fetched 119 kB in 1s (184 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm2 amd64 2.4.113-2~ubuntu0.22.04.1 [38.1 kB]\n",
      "Fetched 38.1 kB in 0s (85.2 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon0 amd64 1.4.0-1 [125 kB]\n",
      "Fetched 125 kB in 1s (188 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgbm1 amd64 23.2.1-1ubuntu3.1~22.04.3 [33.5 kB]\n",
      "Fetched 33.5 kB in 0s (80.3 kB/s)\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libasound2 amd64 1.2.6.1-1ubuntu1 [390 kB]\n",
      "Fetched 390 kB in 1s (461 kB/s)\n",
      "LD_LIBRARY_PATH установлен: /home/jovyan/playwright-deps/usr/lib/x86_64-linux-gnu:\n",
      "Зависимости успешно установлены!\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from email.utils import parsedate_to_datetime\n",
    "from argon2.low_level import hash_secret_raw, Type\n",
    "import base64\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from playwright.sync_api import sync_playwright\n",
    "from playwright.async_api import async_playwright\n",
    "import cloudscraper\n",
    "import tempfile\n",
    "import asyncio\n",
    "from enum import Enum\n",
    "import re\n",
    "import html\n",
    "from tabulate import tabulate\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "from typing import List, Optional, Dict, Any\n",
    "try:\n",
    "    # Для webdriver_manager >= 3.8.0\n",
    "    from webdriver_manager.core.os_manager import ChromeType\n",
    "except ImportError:\n",
    "    # Для старых версий\n",
    "    from webdriver_manager.core.utils import ChromeType\n",
    "\n",
    "    \n",
    "class ContentType(Enum):\n",
    "    RAW_RSS = \"raw_rss\"\n",
    "    HTML_RSS = \"html_rss\"\n",
    "    RAW_ATOM = \"raw_atom\"         # Чистый Atom/XML без обертки\n",
    "    HTML_ATOM = \"html_atom\"       # Atom завернутый в HTML\n",
    "    ANUBIS = \"anubis\"             # Страница проверки Anubis\n",
    "    PLAIN_TEXT = \"plain_text\"     # Простой текст\n",
    "    OTHER = \"other\"               # Другой тип контента\n",
    "\n",
    "@dataclass\n",
    "class NewsEntry:\n",
    "    title: str\n",
    "    link: str\n",
    "    id: str\n",
    "    updated: str\n",
    "    summary: Optional[str] = None\n",
    "    content: Optional[str] = None\n",
    "    @classmethod\n",
    "    def get_field_names(cls) -> List[str]:\n",
    "        return [f.name for f in fields(cls)]\n",
    "    def to_table_row(\n",
    "        self,\n",
    "        fields: List[str] = None,\n",
    "        max_length: int = 50,\n",
    "        truncate: bool = True\n",
    "    ) -> List[str]:\n",
    "        # Если поля не указаны, используем все доступные\n",
    "        if fields is None:\n",
    "            fields = [f.name for f in fields(self.__class__)]\n",
    "        \n",
    "        row = []\n",
    "        for field in fields:\n",
    "            # Получаем значение поля\n",
    "            value = getattr(self, field, \"\")\n",
    "            \n",
    "            # Обработка None значений\n",
    "            if value is None:\n",
    "                row.append(\"\")\n",
    "                continue\n",
    "                \n",
    "            # Преобразование в строку\n",
    "            value_str = str(value)\n",
    "            \n",
    "            # Обрезка длинного текста\n",
    "            if truncate and len(value_str) > max_length:\n",
    "                value_str = value_str[:max_length-3] + \"...\"\n",
    "                \n",
    "            row.append(value_str)\n",
    "        return row\n",
    "\n",
    "def display_news_entries(\n",
    "    entries: List[NewsEntry],\n",
    "    fields: Optional[List[str]] = None,\n",
    "    max_length: int = 50,\n",
    "    truncate: bool = True,\n",
    "    tablefmt: str = \"grid\",\n",
    "    show_index: bool = True\n",
    ") -> str:\n",
    "    if fields is None:\n",
    "        fields = ['title', 'link', 'updated']\n",
    "    \n",
    "    # Проверяем допустимость полей\n",
    "    available_fields = NewsEntry.get_field_names()\n",
    "    for field in fields:\n",
    "        if field not in available_fields:\n",
    "            raise ValueError(f\"Недопустимое поле: {field}. Допустимые поля: {available_fields}\")\n",
    "    \n",
    "    table_data = [entry.to_table_row(fields, max_length, truncate) for entry in entries]\n",
    "\n",
    "    return tabulate(\n",
    "        table_data,\n",
    "        headers=fields,\n",
    "        tablefmt=tablefmt,\n",
    "        maxcolwidths=max_length,\n",
    "        showindex=list(range(len(entries))) if show_index else None,\n",
    "        colalign=(\"left\",) * len(fields)\n",
    "    )\n",
    "\n",
    "\n",
    "def try_scraper(url) -> str:\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    return scraper.get(url).text\n",
    "\n",
    "def is_html_valid(input_str: str) -> bool:\n",
    "    soup = BeautifulSoup(input_str, 'html.parser')\n",
    "    return bool(soup.find() or \n",
    "                soup.contents or \n",
    "                isinstance(soup, BeautifulSoup))\n",
    "\n",
    "\n",
    "def install_chromium_conda():\n",
    "    \"\"\"Устанавливает Chromium через Conda\"\"\"\n",
    "    print(\"Установка Chromium через Conda...\")\n",
    "    try:\n",
    "        # Проверяем, запущены ли мы в Jupyter\n",
    "        if 'ipykernel' in sys.modules:\n",
    "            get_ipython().system('conda install -c conda-forge chromium-browser -y')\n",
    "            get_ipython().system('conda install -c conda-forge chromedriver -y')\n",
    "        else:\n",
    "            subprocess.run(['conda', 'install', '-c', 'conda-forge', 'chromium-browser', '-y'], check=True)\n",
    "            subprocess.run(['conda', 'install', '-c', 'conda-forge', 'chromedriver', '-y'], check=True)\n",
    "        print(\"Установка завершена\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка установки: {e}\")\n",
    "        return False\n",
    "        \n",
    "def get_chromium_path():\n",
    "    \"\"\"Возвращает путь к Chromium в Conda\"\"\"\n",
    "    conda_prefix = os.environ.get('CONDA_PREFIX', '')\n",
    "    paths = [\n",
    "        os.path.join(conda_prefix, 'bin', 'chromium'),\n",
    "        os.path.join(conda_prefix, 'bin', 'chromium-browser'),\n",
    "        os.path.join(conda_prefix, 'Library', 'bin', 'chromium.exe'),\n",
    "    ]\n",
    "    \n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def install_playwright_deps_local():\n",
    "    \"\"\"Устанавливает зависимости локально без root-прав\"\"\"\n",
    "    print(\"Установка локальных зависимостей для Playwright...\")\n",
    "    try:\n",
    "        # Создаем директорию для зависимостей\n",
    "        home_dir = os.path.expanduser(\"~\")\n",
    "        deps_dir = os.path.join(home_dir, \"playwright-deps\")\n",
    "        os.makedirs(deps_dir, exist_ok=True)\n",
    "        \n",
    "        # Устанавливаем необходимые пакеты в локальную директорию\n",
    "        deps = [\n",
    "            \"libatk1.0-0\", \"libatk-bridge2.0-0\", \"libxcomposite1\",\n",
    "            \"libxdamage1\", \"libatspi2.0-0\", \"libnss3\", \"libnspr4\",\n",
    "            \"libdrm2\", \"libxkbcommon0\", \"libgbm1\", \"libasound2\"\n",
    "        ]\n",
    "        \n",
    "        for dep in deps:\n",
    "            # Скачиваем пакет\n",
    "            download_cmd = f\"apt-get download {dep}\"\n",
    "            subprocess.run(download_cmd, shell=True, check=True, cwd=deps_dir)\n",
    "            \n",
    "            # Находим скачанный файл\n",
    "            deb_file = next((f for f in os.listdir(deps_dir) if f.endswith(\".deb\") and dep in f), None)\n",
    "            if not deb_file:\n",
    "                print(f\"Не удалось найти .deb файл для {dep}\")\n",
    "                continue\n",
    "                \n",
    "            # Распаковываем пакет\n",
    "            deb_path = os.path.join(deps_dir, deb_file)\n",
    "            extract_cmd = f\"dpkg-deb -x {deb_path} {deps_dir}\"\n",
    "            subprocess.run(extract_cmd, shell=True, check=True)\n",
    "            \n",
    "            # Удаляем .deb файл после распаковки\n",
    "            os.remove(deb_path)\n",
    "        \n",
    "        # Настраиваем переменные окружения\n",
    "        lib_path = os.path.join(deps_dir, \"usr\", \"lib\", \"x86_64-linux-gnu\")\n",
    "        os.environ[\"LD_LIBRARY_PATH\"] = f\"{lib_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "        print(f\"LD_LIBRARY_PATH установлен: {os.environ['LD_LIBRARY_PATH']}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка установки зависимостей: {e}\")\n",
    "        return False\n",
    "        \n",
    "if not os.environ.get(\"PLAYWRIGHT_DEPS_INSTALLED\"):\n",
    "    if install_playwright_deps_local():\n",
    "        os.environ[\"PLAYWRIGHT_DEPS_INSTALLED\"] = \"1\"\n",
    "        print(\"Зависимости успешно установлены!\")\n",
    "    else:\n",
    "        print(\"Продолжаем без зависимостей - возможны проблемы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3105767c-db92-46fd-80b6-776279a73e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_content_type(content: str) -> ContentType:\n",
    "    \"\"\"\n",
    "    Определяет тип контента\n",
    "    :param content: Строка с контентом\n",
    "    :return: Тип контента как ContentType\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return ContentType.OTHER\n",
    "    \n",
    "    # Детектор Anubis\n",
    "    if is_anubis_page(content):\n",
    "        return ContentType.ANUBIS\n",
    "    \n",
    "\n",
    "    if is_raw_atom(content):\n",
    "        return ContentType.RAW_ATOM\n",
    "    if is_raw_rss(content):\n",
    "        return ContentType.RAW_RSS\n",
    "\n",
    "    if is_html_wrapped_rss(content):\n",
    "        return ContentType.HTML_RSS\n",
    "    if is_html_wrapped_atom(content):\n",
    "        return ContentType.HTML_ATOM\n",
    "    \n",
    "    # Детектор plain text\n",
    "    if is_plain_text(content):\n",
    "        return ContentType.PLAIN_TEXT\n",
    "    \n",
    "    return ContentType.OTHER\n",
    "\n",
    "def is_anubis_page(content: str) -> bool:\n",
    "    \"\"\"Проверяет, является ли контент страницей Anubis\"\"\"\n",
    "    content = html.unescape(content)\n",
    "    anubis_indicators = [\n",
    "        \"Making sure you're not a bot!\",\n",
    "        \"Protected by Anubis\",\n",
    "        \"id=\\\"progress\\\"\",\n",
    "        \"id=\\\"status\\\"\",\n",
    "        \"anubis_version\",\n",
    "        \"/anubis/static/img/\"\n",
    "    ]\n",
    "    return any(indicator in content for indicator in anubis_indicators)\n",
    "\n",
    "def is_raw_rss(content: str) -> bool:\n",
    "    content = html.unescape(content)\n",
    "    return content.lstrip().startswith(('<?xml', '<rss')) and (\"<rss\" in content)\n",
    "def is_html_wrapped_rss(content: str) -> bool:\n",
    "    html_indicators = ['<html', '<head', '<body']\n",
    "    return (not is_raw_rss(content)) and (\"<rss\" in content) and any(indicator in content for indicator in html_indicators)\n",
    "    \n",
    "def is_raw_atom(content: str) -> bool:\n",
    "    content = html.unescape(content)\n",
    "    \"\"\"Проверяет, является ли контент чистым Atom без HTML-обертки\"\"\"\n",
    "    # Проверяем начало документа\n",
    "    if not content.lstrip().startswith(('<?xml', '<feed')):\n",
    "        return False\n",
    "    \n",
    "    # Проверяем основные элементы Atom\n",
    "    atom_indicators = [\n",
    "        '<feed', '</feed>',\n",
    "        'xmlns=\"http://www.w3.org/2005/Atom\"',\n",
    "        '<entry>', '</entry>',\n",
    "        '<id>', '</id>',\n",
    "        '<title>', '</title>',\n",
    "        '<updated>', '</updated>'\n",
    "    ]\n",
    "    \n",
    "    return all(indicator in content for indicator in atom_indicators)\n",
    "\n",
    "def is_html_wrapped_atom(content: str) -> bool:\n",
    "    content = html.unescape(content)\n",
    "    \"\"\"Проверяет, содержит ли HTML-контент Atom в обертке\"\"\"\n",
    "    # Должны быть признаки HTML\n",
    "    html_indicators = ['<html', '<head', '<body', '<meta', '<div', '<pre']\n",
    "    if not any(indicator in content for indicator in html_indicators):\n",
    "        return False\n",
    "    \n",
    "    # И при этом признаки Atom внутри\n",
    "    atom_indicators = ['<feed', '</feed>', '<entry>', 'xmlns=\"http://www.w3.org/2005/Atom\"']\n",
    "    return any(indicator in content for indicator in atom_indicators)\n",
    "\n",
    "def is_plain_text(content: str) -> bool:\n",
    "    content = html.unescape(content)\n",
    "    \"\"\"Проверяет, является ли контент простым текстом\"\"\"\n",
    "    # Если контент содержит менее 5% HTML-тегов\n",
    "    tags = re.findall(r'<[^>]+>', content)\n",
    "    tag_ratio = len(tags) / (len(content) / 100) if content else 0\n",
    "    \n",
    "    # Дополнительные признаки текста\n",
    "    text_indicators = [\n",
    "        len(content.splitlines()) > 10,  # Много строк\n",
    "        '\\n' in content,                 # Переносы строк\n",
    "        tag_ratio < 5,                   # Мало тегов\n",
    "        not content.startswith('<')       # Не начинается с тега\n",
    "    ]\n",
    "    \n",
    "    return all(text_indicators)\n",
    "def extract_xml(html_str: str) -> str:\n",
    "    html_str = html.unescape(html_str)\n",
    "    # Определяем маркеры начала и конца\n",
    "    start_marker = \"<?xml\"\n",
    "    end_marker = \"</feed>\"\n",
    "    \n",
    "    # Ищем начало XML\n",
    "    start_idx = html_str.find(start_marker)\n",
    "    if start_idx == -1:\n",
    "        return \"\"  # Начало не найдено\n",
    "    \n",
    "    # Ищем конец корневого элемента\n",
    "    end_idx = html_str.find(end_marker, start_idx)\n",
    "    \n",
    "    # Извлекаем подстроку (с учётом длины end_marker)\n",
    "    if end_idx == -1:\n",
    "        xml_escaped = html_str[start_idx:]  # До конца строки\n",
    "    else:\n",
    "        xml_escaped = html_str[start_idx:end_idx + len(end_marker)]\n",
    "    \n",
    "    return xml_escaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddeef71b-555b-46dc-aa52-0a39af14ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка URL: https://lore.kernel.org/all/new.atom\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "|    | title                                              | link                                               | updated              |\n",
      "+====+====================================================+====================================================+======================+\n",
      "| 0  | Re: [PATCH 4/5] staging: vchiq_arm: Create keep... | https://lore.kernel.org/all/0c2840c2-241c-4f98-... | 2025-06-28T22:34:18Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 1  | [PATCH] wifi: rtw88: enable TX reports for the ... | https://lore.kernel.org/all/20250628223048.3597... | 2025-06-28T22:34:05Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 2  | Re: [PULL REQUEST] i2c-for-6.16-rc4                | https://lore.kernel.org/all/175114999690.230075... | 2025-06-28T22:32:51Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 3  | [PATCH v2] test: Wait for output to flush out i... | https://lore.kernel.org/all/20250628223050.3396... | 2025-06-28T22:30:57Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 4  | RTT-PROBE: lore-subspace-rtt                       | https://lore.kernel.org/all/175114979357.31417.... | 2025-06-28T22:29:53Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 5  | Re: [PATCH net/next 3/3] net: ethernet: mtk_eth... | https://lore.kernel.org/all/202506290627.8dPD2P... | 2025-06-28T22:25:18Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 6  | [gdamjan:wip/ipu7-imx471 2/4] drivers/media/pci... | https://lore.kernel.org/all/202506290640.PNXIsr... | 2025-06-28T22:25:15Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 7  | Re: [PATCH v1 0/4] net/ntnic: implement start, ... | https://lore.kernel.org/all/20250628152059.3657... | 2025-06-28T22:21:07Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 8  | [PATCH v2] arch/arm/include/asm/arch-imxrt/gpio... | https://lore.kernel.org/all/20250628221944.2412... | 2025-06-28T22:20:01Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 9  | RTT-PROBE: lore-subspace-rtt                       | https://lore.kernel.org/all/175114919357.5311.4... | 2025-06-28T22:19:53Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 10 | Re: [GIT PULL] tracing: Fixes for v6.16            | https://lore.kernel.org/all/175114920836.229792... | 2025-06-28T22:19:42Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 11 | Re: [GIT PULL] LoongArch fixes for v6.16-rc4       | https://lore.kernel.org/all/175114920694.229792... | 2025-06-28T22:19:41Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 12 | Re: [PATCH net-next 3/4] tcp: move tcp_memory_a... | https://lore.kernel.org/all/202506290837.0mGwXg... | 2025-06-28T22:15:16Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 13 | Re: [PATCH] powercap: dtpm_cpu: Fix NULL pointe... | https://lore.kernel.org/all/CAFcvxdMozCv1mJFKem... | 2025-06-28T22:13:03Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 14 | Re: [PATCH] arch/arm/include/asm/arch-imxrt/gpi... | https://lore.kernel.org/all/9328607c-51f3-4579-... | 2025-06-28T22:11:51Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 15 | linux-next: Signed-off-by missing for commit in... | https://lore.kernel.org/all/20250629080950.2933... | 2025-06-28T22:10:22Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 16 | RTT-PROBE: lore-subspace-rtt                       | https://lore.kernel.org/all/175114859357.11710.... | 2025-06-28T22:09:53Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 17 | Re: [RFC v2 1/9] sched/docs: Document avoid_cpu... | https://lore.kernel.org/all/20250628220230.2052... | 2025-06-28T22:02:50Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 18 | RTT-PROBE: lore-subspace-rtt                       | https://lore.kernel.org/all/175114799357.14430.... | 2025-06-28T21:59:53Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 19 | [PATCH 5/5] arm64: dts: renesas: sparrow-hawk: ... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:36Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 20 | [PATCH 4/5] arm64: dts: renesas: sparrow-hawk: ... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:33Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 21 | [PATCH 3/5] arm64: dts: renesas: sparrow-hawk: ... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:31Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 22 | [PATCH 2/5] arm64: dts: renesas: sparrow-hawk: ... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:29Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 23 | [PATCH 1/5] arm64: dts: renesas: r8a779g3-sparr... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:26Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n",
      "| 24 | [PATCH 0/5] arm64: dts: renesas: sparrow-hawk: ... | https://lore.kernel.org/all/20250628215337.1688... | 2025-06-28T21:56:24Z |\n",
      "+----+----------------------------------------------------+----------------------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "async def get_content_with_anubis(url, timeout=60):\n",
    "    \"\"\"\n",
    "    Получает контент страницы после прохождения проверки Anubis\n",
    "    :param url: URL для загрузки\n",
    "    :param timeout: максимальное время ожидания в секундах\n",
    "    :return: HTML-контент страницы\n",
    "    \"\"\"\n",
    "    p = await async_playwright().start()\n",
    "    # Запускаем Chromium в headless-режиме\n",
    "    browser = await p.chromium.launch(headless=True)\n",
    "    context = await browser.new_context(\n",
    "        user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "        viewport={\"width\": 1920, \"height\": 1080}\n",
    "    )\n",
    "    page = await context.new_page()\n",
    "    \n",
    "    # Переходим на страницу\n",
    "    print(f\"Загрузка URL: {url}\")\n",
    "    await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "    \n",
    "    try:\n",
    "        # Ожидание появления элементов Anubis\n",
    "        initial_content = await page.content()\n",
    "        initial_content = html.unescape(initial_content)\n",
    "        c_type = detect_content_type(initial_content)\n",
    "        if c_type == ContentType.HTML_ATOM:\n",
    "            x = extract_xml(initial_content)\n",
    "            c = detect_content_type(x)\n",
    "            if c != ContentType.RAW_ATOM:\n",
    "                raise ValueError(f\"cannot extract atom from [[ {initial_content[:256]} ]] is not an atom [[ {x[:256]} ]] detected as {c.name}\")\n",
    "            return x, ContentType.RAW_ATOM\n",
    "        elif c_type != ContentType.ANUBIS:\n",
    "            return initial_content, c_type\n",
    "            \n",
    "\n",
    "        print(\"Ожидание проверки Anubis...\")\n",
    "        await page.wait_for_selector(\"text=Making sure you're not a bot!\", timeout=timeout*1000)\n",
    "        \n",
    "        # Ожидание завершения progress bar\n",
    "        try:\n",
    "            progress_bar = page.locator(\"#progress\")\n",
    "            print(\"Ожидание завершения progress bar...\")\n",
    "            \n",
    "            # Мониторим изменение progress bar\n",
    "            start_time = time.time()\n",
    "            while time.time() - start_time < timeout:\n",
    "                class_list = progress_bar.get_attribute(\"class\") or \"\"\n",
    "                if \"hidden\" in class_list or \"invisible\" in class_list:\n",
    "                    print(\"Progress bar скрыт!\")\n",
    "                    break\n",
    "                await asyncio.sleep(0.5)\n",
    "            else:\n",
    "                print(\"Таймаут ожидания progress bar\")\n",
    "        except:\n",
    "            print(\"Progress bar не найден, используем fallback ожидание\")\n",
    "            await page.wait_for_timeout(15000)  # 15 секунд\n",
    "        \n",
    "        # Дополнительное ожидание выполнения скриптов\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "        \n",
    "        # Проверка результата\n",
    "        if  await page.query_selector(\"text=Making sure you're not a bot!\"):\n",
    "            print(\"Проверка Anubis не пройдена!\")\n",
    "            return None\n",
    "        \n",
    "        print(\"Проверка Anubis пройдена!\")\n",
    "        return await page.content()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        await page.screenshot(path=\"anubis_error.png\")\n",
    "        print(\"Скриншот сохранен как anubis_error.png\")\n",
    "        return None\n",
    "    finally:\n",
    "        await browser.close()\n",
    "\n",
    "def parse_atom(xml_content: str) -> List[NewsEntry]:\n",
    "    # Парсим XML с помощью feedparser\n",
    "    feed = feedparser.parse(xml_content)\n",
    "    entries = []\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        # Обработка контента (может быть в нескольких форматах)\n",
    "        content_value = None\n",
    "        if hasattr(entry, 'content'):\n",
    "            for item in entry.content:\n",
    "                if hasattr(item, 'value'):\n",
    "                    content_value = item.value\n",
    "                    break\n",
    "        \n",
    "        # Обработка даты обновления\n",
    "        updated_str = \"\"\n",
    "        if hasattr(entry, 'updated_parsed'):\n",
    "            updated_str = time.strftime('%Y-%m-%dT%H:%M:%SZ', entry.updated_parsed)\n",
    "        elif hasattr(entry, 'updated'):\n",
    "            updated_str = entry.updated\n",
    "        \n",
    "        # Создаем объект записи\n",
    "        entries.append(NewsEntry(\n",
    "            title=entry.title,\n",
    "            link=entry.link,\n",
    "            id=entry.id,\n",
    "            updated=updated_str,\n",
    "            summary=entry.get('summary'),\n",
    "            content=content_value\n",
    "        ))\n",
    "    \n",
    "    return entries\n",
    "\n",
    "# Пример использования\n",
    "async def main():\n",
    "    URL = \"https://lore.kernel.org/all/new.atom\"\n",
    "    content, content_type = await  get_content_with_anubis(URL)\n",
    "    if not content:\n",
    "        raise ValueError(\"Не удалось загрузить контент\")\n",
    "    if content_type == ContentType.RAW_ATOM:\n",
    "        news = parse_atom(content)\n",
    "        print(display_news_entries(news))\n",
    "            \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616f62-61cd-4408-963b-9840dce06e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
